{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68dfb620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 1, out_channels = 16, kernel_size = 5),  \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = 5),\n",
    "        )\n",
    "\n",
    "        self.decoder1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels = 32, out_channels= 16, kernel_size = 5),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels = 16, out_channels= 1, kernel_size = 5),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, return_features=False):\n",
    "        encoded1 = self.encoder1(x)\n",
    "        if return_features:\n",
    "            return encoded1  \n",
    "        decoded1 = self.decoder1(encoded1)\n",
    "        return decoded1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1d437cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resim yükleme ve dönüştürme işlemleri\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((28, 28)),  # Resimleri 28x28 boyutuna küçültüyoruz\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize etme işlemi (Sonradan ekledim.)\n",
    "])\n",
    "\n",
    "# Train ve Test datasetlerini yükleme\n",
    "train_data = datasets.ImageFolder(root='../train', transform=transform)\n",
    "test_data = datasets.ImageFolder(root='../test', transform=transform)\n",
    "\n",
    "# DataLoader ile veri kümelerini yükleme\n",
    "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=16, shuffle=True)\n",
    "\n",
    "# Modeli başlatma\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Autoencoder().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "388c5c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.0542\n",
      "Patience counter of epoch 1 is 0\n",
      "Epoch [2/100], Loss: 0.0316\n",
      "Patience counter of epoch 2 is 0\n",
      "Epoch [3/100], Loss: 0.0282\n",
      "Patience counter of epoch 3 is 0\n",
      "Epoch [4/100], Loss: 0.0269\n",
      "Patience counter of epoch 4 is 0\n",
      "Epoch [5/100], Loss: 0.0262\n",
      "Patience counter of epoch 5 is 1\n",
      "Epoch [6/100], Loss: 0.0257\n",
      "Patience counter of epoch 6 is 0\n",
      "Epoch [7/100], Loss: 0.0253\n",
      "Patience counter of epoch 7 is 1\n",
      "Epoch [8/100], Loss: 0.0251\n",
      "Patience counter of epoch 8 is 2\n",
      "Epoch [9/100], Loss: 0.0249\n",
      "Patience counter of epoch 9 is 3\n",
      "Epoch [10/100], Loss: 0.0247\n",
      "Patience counter of epoch 10 is 4\n",
      "Epoch [11/100], Loss: 0.0246\n",
      "Patience counter of epoch 11 is 0\n",
      "Epoch [12/100], Loss: 0.0245\n",
      "Patience counter of epoch 12 is 1\n",
      "Epoch [13/100], Loss: 0.0244\n",
      "Patience counter of epoch 13 is 2\n",
      "Epoch [14/100], Loss: 0.0244\n",
      "Patience counter of epoch 14 is 3\n",
      "Epoch [15/100], Loss: 0.0243\n",
      "Patience counter of epoch 15 is 4\n",
      "Epoch [16/100], Loss: 0.0242\n",
      "Patience counter of epoch 16 is 5\n",
      "Early stopping triggered at epoch 16\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Eğitim ayarları\n",
    "num_epochs = 100\n",
    "#learning_rate = 0.001\n",
    "\n",
    "# Kayıp fonksiyonu ve optimizer\n",
    "criterion = nn.MSELoss()  # Mean Squared Error kaybı\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# Modeli eğitme fonksiyonu\n",
    "def train_autoencoder(model, train_loader, criterion, optimizer, num_epochs, patience=5, delta=0.001):\n",
    "    model.train()  # Modeli eğitim moduna alıyoruz\n",
    "    \n",
    "    best_loss = float('inf')  # En iyi kayıp değeri\n",
    "    patience_counter = 0  # Patience sayacı\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for data, _ in train_loader:  # Giriş verisi ve etiketler (etiketler kullanılmaz çünkü reconstruct ediliyor)\n",
    "            data = data.to(device)\n",
    "            \n",
    "            # İleri yayılım (forward pass)\n",
    "            output = model(data)\n",
    "            \n",
    "            # Kayıp hesaplama\n",
    "            loss = criterion(output, data)  # Girdi veri ile çıktı veri arasındaki fark\n",
    "            \n",
    "            # Geri yayılım (backpropagation) ve optimizasyon\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Her epoch sonunda ortalama kaybı yazdırma\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "        \n",
    "        # Early stopping kontrolü\n",
    "        if epoch_loss < best_loss - delta:\n",
    "            best_loss = epoch_loss  # En iyi loss güncelleniyor\n",
    "            patience_counter = 0  # Patience sayacı sıfırlanıyor\n",
    "        else:\n",
    "            patience_counter += 1  # Eğer gelişme yoksa patience artırılır\n",
    "        \n",
    "        print(f\"Patience counter of epoch {epoch+1} is {patience_counter}\")\n",
    "        \n",
    "        # Eğer patience counter belirlenen değeri aşarsa durdur\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "\n",
    "# Modeli eğitme\n",
    "train_autoencoder(model, train_loader, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ebf8d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(loader, model):\n",
    "    model.eval()  # Modeli eval moduna alıyoruz\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    with torch.no_grad():  \n",
    "        for data, label in loader:\n",
    "            data = data.to(device)\n",
    "            output = model(data, return_features=True)  \n",
    "            output = output.view(output.size(0), -1)  \n",
    "            features.append(output.cpu().numpy())\n",
    "            labels.append(label.cpu().numpy())\n",
    "    \n",
    "    features = np.vstack(features)\n",
    "    labels = np.hstack(labels)\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a66e47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ve Test veri setleri başarıyla kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "# Train ve Test veri setlerinden özellikler çıkarıyoruz\n",
    "train_features, train_labels = extract_features(train_loader, model)\n",
    "test_features, test_labels = extract_features(test_loader, model)\n",
    "\n",
    "# Özellik ve etiket dosyalarını .npy olarak kaydetme\n",
    "np.save('train_features_autoencoder.npy', train_features)\n",
    "np.save('train_labels_autoencoder.npy', train_labels)\n",
    "np.save('test_features_autoencoder.npy', test_features)\n",
    "np.save('test_labels_autoencoder.npy', test_labels)\n",
    "\n",
    "print(\"Train ve Test veri setleri başarıyla kaydedildi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b73b4f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeli kaydetme\n",
    "torch.save(model.state_dict(), 'model_ae.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8a02ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
